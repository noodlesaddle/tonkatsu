---
title: Basic Go project
description:  Extracting data from websites using Go.

---


# Building a Web Scraper in Go Language

Web scraping is a technique of extracting data from websites. It involves parsing the HTML content of a website and extracting specific information based on certain patterns. In this tutorial, we will learn how to build a web scraper in Go language using the `goquery` package.






Before we get started, you will need to have Go language installed on your system. You can download the latest version of Go from the official website: [https://golang.org/dl/](https://golang.org/dl/).

You will also need the `goquery` package, which can be installed using the following command:

```
go get github.com/PuerkitoBio/goquery
```

## Building a Web Scraper

Let's get started by building a simple web scraper that fetches all the links from a web page. Here's the code:


```go
package main

import (
    "fmt"
    "log"
    "net/http"

    "github.com/PuerkitoBio/goquery"
)

func main() {
    // Fetch the web page
    res, err := http.Get("https://example.com")
    if err != nil {
        log.Fatal(err)
    }
    defer res.Body.Close()

    // Parse the HTML content
    doc, err := goquery.NewDocumentFromReader(res.Body)
    if err != nil {
        log.Fatal(err)
    }

    // Extract all the links
    doc.Find("a").Each(func(i int, s *goquery.Selection) {
        link, _ := s.Attr("href")
        fmt.Printf("%d: %s\n", i, link)
    })
}

````
## Conclusion

From this example project I learned about web scrapping concept, and goquery package that parses HTML and extracts data, and also goquery.NewDocumentFromReader() function which takes a reader as input and returns a document object.
I will continue to build more small projects in Go and update this project.